{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs,in_channels,out_channels):\n",
    "    net=[nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1),nn.ReLU()]\n",
    "    for i in range(num_convs-1):\n",
    "        net.append(nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1))\n",
    "        net.append(nn.ReLU())\n",
    "    \n",
    "    net.append(nn.MaxPool2d(2,2))\n",
    "    return nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_stack(num_convs,channels):\n",
    "    net=[]\n",
    "    for n,c in zip(num_convs,channels):\n",
    "        in_channels=c[0]\n",
    "        out_channels=c[1]\n",
    "        net.append(vgg_block(n,in_channels,out_channels))\n",
    "    return nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vggnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vggnet,self).__init__()\n",
    "        self.feature=vgg_stack((1, 1, 2, 2, 2), ((3, 64), (64, 128), (128, 256), (256, 512), (512, 512)))\n",
    "        self.classify=nn.Sequential(\n",
    "            nn.Linear(512,200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200,10),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.feature(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classify(x)\n",
    "        return x\n",
    "\n",
    "net=vggnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tf(x):\n",
    "    x=np.array(x,dtype='float32')/255\n",
    "    x=(x-0.5)/0.5\n",
    "    x=x.transpose((2,0,1))\n",
    "    x=torch.from_numpy(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor([[ 1.0000,  1.0000,  1.0000,  ...,  0.5312,  0.6641,  0.4297],\n",
      "        [ 1.0000,  0.9922,  0.9922,  ...,  0.3359,  0.2656,  0.1484],\n",
      "        [ 1.0000,  0.9922,  1.0000,  ...,  0.4844,  0.3047, -0.0469],\n",
      "        ...,\n",
      "        [ 0.1641,  0.1172,  0.1016,  ..., -0.7578, -0.4844, -0.3984],\n",
      "        [-0.0391, -0.0547, -0.0078,  ..., -0.8203, -0.2344,  0.1094],\n",
      "        [-0.3125, -0.3047, -0.2031,  ..., -0.7266, -0.1719,  0.0859]])\n"
     ]
    }
   ],
   "source": [
    "train_set=CIFAR10('./data',train=True,transform=data_tf, download=True)\n",
    "test_set=CIFAR10('./data',train=False,transform=data_tf, download=True)\n",
    "print(train_set[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().item()\n",
    "    return num_correct / total\n",
    "\n",
    "def set_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data, valid_data, num_epochs, optimizer, criterion):\n",
    "    prev_time = datetime.now()\n",
    "    net=net.cuda()\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch==15:\n",
    "            set_learning_rate(optimizer,1e-2)\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        net = net.train()\n",
    "        for im, label in train_data:\n",
    "            im = Variable(im)\n",
    "            label = Variable(label)\n",
    "            im=im.cuda()\n",
    "            label=label.cuda()\n",
    "            # forward\n",
    "            output = net(im)\n",
    "            loss = criterion(output, label)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_acc(output, label)\n",
    "            \n",
    "        cur_time = datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        \n",
    "        if valid_data is not None:\n",
    "            valid_loss = 0\n",
    "            valid_acc = 0\n",
    "            net = net.eval()\n",
    "            for im, label in valid_data:\n",
    "                im = Variable(im, volatile=True)\n",
    "                label = Variable(label, volatile=True)\n",
    "                im=im.cuda()\n",
    "                label=label.cuda()\n",
    "                \n",
    "                output = net(im)\n",
    "                loss = criterion(output, label)\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "                valid_acc += get_acc(output, label)\n",
    "            epoch_str = (\n",
    "                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n",
    "                % (epoch, train_loss / len(train_data),\n",
    "                   train_acc / len(train_data), valid_loss / len(valid_data),\n",
    "                   valid_acc / len(valid_data)))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, \" %\n",
    "                         (epoch, train_loss / len(train_data),\n",
    "                          train_acc / len(train_data)))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1) # 使用随机梯度下降，学习率 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 2.925825, Train Acc: 0.248481, Valid Loss: 3.085552, Valid Acc: 0.220926, Time 00:00:42\n",
      "Epoch 1. Train Loss: 2.864115, Train Acc: 0.261449, Valid Loss: 3.006512, Valid Acc: 0.243473, Time 00:00:45\n",
      "Epoch 2. Train Loss: 2.801509, Train Acc: 0.273438, Valid Loss: 3.322412, Valid Acc: 0.189873, Time 00:00:45\n",
      "Epoch 3. Train Loss: 2.736911, Train Acc: 0.288103, Valid Loss: 2.858321, Valid Acc: 0.267306, Time 00:00:45\n",
      "Epoch 4. Train Loss: 2.675574, Train Acc: 0.298414, Valid Loss: 3.238603, Valid Acc: 0.214695, Time 00:00:45\n"
     ]
    }
   ],
   "source": [
    "train(net,train_data,test_data,20,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
