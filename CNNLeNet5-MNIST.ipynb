{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):            \n",
    "        super(LeNet5,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*4*4,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        #x=x.view(-1,self.num_feature(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def num_feature(x):\n",
    "        size=x.size()[1:] #除 了batch维度外的size\n",
    "        num=1\n",
    "        for s in size:\n",
    "            num*=s\n",
    "        return num\n",
    "\n",
    "net=LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.1226,  0.1347, -0.0456,  0.0330,  0.0242],\n",
      "          [-0.1411,  0.0318,  0.1375,  0.0863,  0.0974],\n",
      "          [ 0.0476,  0.1202,  0.0639, -0.1113, -0.0474],\n",
      "          [ 0.1993,  0.1792, -0.1009,  0.1733, -0.0313],\n",
      "          [-0.0106,  0.1715, -0.0557,  0.0424,  0.0604]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0793,  0.1044, -0.1555,  0.0484, -0.1154],\n",
      "          [-0.0040, -0.1498,  0.0778,  0.0688, -0.0038],\n",
      "          [ 0.0222,  0.1041,  0.0944, -0.0759,  0.1170],\n",
      "          [ 0.0897, -0.1792, -0.0655,  0.1935, -0.0540],\n",
      "          [-0.0044,  0.1258, -0.1332,  0.1713,  0.0547]]],\n",
      "\n",
      "\n",
      "        [[[-0.1979, -0.0432, -0.0947, -0.1417,  0.1269],\n",
      "          [ 0.1446,  0.0166,  0.0835, -0.1418, -0.1900],\n",
      "          [-0.1536,  0.1150,  0.0581,  0.0904, -0.1142],\n",
      "          [ 0.0632, -0.0834, -0.1349,  0.1824, -0.1178],\n",
      "          [ 0.1205,  0.0644,  0.0648,  0.0111, -0.1547]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1830,  0.1759,  0.1250, -0.0054,  0.1459],\n",
      "          [ 0.0627,  0.0394,  0.0658, -0.1398,  0.1930],\n",
      "          [-0.0090, -0.1029,  0.1355,  0.1442, -0.1490],\n",
      "          [ 0.1304,  0.1364, -0.0796,  0.0252,  0.0902],\n",
      "          [-0.0959,  0.0055, -0.1333, -0.0370,  0.1623]]],\n",
      "\n",
      "\n",
      "        [[[-0.1820, -0.0112,  0.0966, -0.1165, -0.0859],\n",
      "          [ 0.1062, -0.1826,  0.0305, -0.0989,  0.0284],\n",
      "          [-0.0338,  0.1935, -0.0367,  0.1138,  0.0854],\n",
      "          [-0.1803,  0.1048, -0.1817, -0.0773,  0.0422],\n",
      "          [ 0.1971, -0.0500, -0.0631, -0.1939,  0.0206]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1556, -0.1133,  0.0814, -0.0251,  0.0966],\n",
      "          [ 0.0035,  0.0486, -0.0971, -0.1392, -0.1305],\n",
      "          [-0.0668, -0.0112,  0.1355, -0.1595, -0.1020],\n",
      "          [-0.0359,  0.1428, -0.1252, -0.0662, -0.0430],\n",
      "          [ 0.0020, -0.1682,  0.1123, -0.0939, -0.1010]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for para in net.parameters():\n",
    "    print(para)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets .MNIST('./data', train=True, download=True)\n",
    "test_set = datasets .MNIST('./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def data_tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5 # 标准化，这个技巧之后会讲到\n",
    "    x = transforms.ToTensor()(x)  \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets .MNIST('./data', train=True, transform=data_tf, download=True) # 重新载入数据集，申明定义的数据变换\n",
    "test_set = datasets .MNIST('./data', train=False, transform=data_tf, download=True)\n",
    "print(train_set[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), 1e-1) # 使用随机梯度下降，学习率 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(output, label):\n",
    "    total = output.shape[0]    #output是二维的，零维度是batch，一维度是每个图片的预测标签\n",
    "    _, pred_label = output.max(1)   #output.max(1)结果会返output一维度标签中最大的值和最大标签在一维度中的索引，这里只需用到索引\n",
    "    num_correct = (pred_label == label).sum().item()    #.sum把前面那个张量中所有值加了起来，变成0维tensor，.item（）把它变为数值\n",
    "    return num_correct / total\n",
    "\n",
    "def train(net, train_data, valid_data, num_epochs, optimizer, criterion):\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        net = net.train()\n",
    "        for batchnum,(im, label) in enumerate(train_data):\n",
    "            if torch.cuda.is_available():\n",
    "                im = Variable(im.cuda())  \n",
    "                label = Variable(label.cuda())  \n",
    "            else:\n",
    "                im = Variable(im)\n",
    "                label = Variable(label)\n",
    "            # forward\n",
    "            output = net(im)\n",
    "            loss = criterion(output, label)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 计算误差\n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_acc(output, label)\n",
    "\n",
    "        if valid_data is not None:\n",
    "            valid_loss = 0\n",
    "            valid_acc = 0\n",
    "            net = net.eval()\n",
    "            for batchnum,(im, label) in enumerate(valid_data):\n",
    "                if torch.cuda.is_available():\n",
    "                    im = Variable(im.cuda(), volatile=True)\n",
    "                    label = Variable(label.cuda(), volatile=True)\n",
    "                else:\n",
    "                    im = Variable(im, volatile=True)\n",
    "                    label = Variable(label, volatile=True)\n",
    "                # forward\n",
    "                output = net(im)\n",
    "                loss = criterion(output, label)\n",
    "                # 计算误差\n",
    "                valid_loss += loss.item()\n",
    "                valid_acc += get_acc(output, label)\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \" % (epoch, train_loss / len(train_data),\n",
    "                   train_acc / len(train_data), valid_loss / len(valid_data),valid_acc / len(valid_data)))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, \" %(epoch, train_loss / len(train_data),train_acc / len(train_data)))\n",
    "        \n",
    "        print(epoch_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.397717, Train Acc: 0.864939, Valid Loss: 0.091704, Valid Acc: 0.970728, \n"
     ]
    }
   ],
   "source": [
    "train(net,train_data,test_data,1,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-3.2593e-01,  1.9140e-01,  2.0145e-01,  1.7434e-01, -2.1830e-02],\n",
      "          [-2.3530e-01,  3.0155e-01,  4.6830e-01,  1.3936e-01, -6.0559e-02],\n",
      "          [ 1.6782e-01,  5.4521e-01,  3.0777e-01, -2.5025e-01, -3.0329e-01],\n",
      "          [ 4.3497e-01,  5.1621e-01, -6.6410e-02, -5.9770e-02, -3.0931e-01],\n",
      "          [ 2.5330e-01,  3.8484e-01, -1.1651e-01, -1.9185e-01, -2.1075e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3469e-02,  7.3512e-02, -2.3307e-01, -1.1905e-01, -3.1038e-01],\n",
      "          [ 2.9152e-02, -8.7453e-02,  9.1925e-02, -4.1822e-02, -1.6014e-01],\n",
      "          [ 8.4461e-02,  2.4220e-01,  2.6914e-01, -2.4191e-04,  1.1679e-01],\n",
      "          [ 5.9223e-02, -1.7235e-01,  3.2607e-02,  3.3406e-01,  1.9349e-02],\n",
      "          [-1.3334e-01,  2.7348e-02, -1.9602e-01,  1.6883e-01,  7.4229e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6284e-01, -9.1872e-02, -1.8384e-01, -2.1426e-01,  3.0583e-02],\n",
      "          [ 1.3682e-01, -1.0884e-01, -8.0079e-02, -2.3544e-01, -2.7675e-01],\n",
      "          [-6.1871e-02,  3.3529e-02, -1.0771e-01, -5.7535e-02, -2.5356e-01],\n",
      "          [ 2.4436e-01, -5.0308e-02, -2.3317e-01,  5.2528e-02, -2.0020e-01],\n",
      "          [ 3.4129e-01,  2.1317e-01,  8.9078e-02,  3.0218e-02, -9.1180e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3948e-01,  5.1883e-01,  4.1084e-01,  2.6914e-01,  3.4331e-01],\n",
      "          [ 2.1565e-01,  3.2543e-01,  3.6710e-01,  1.6966e-01,  4.3067e-01],\n",
      "          [-2.0529e-01, -2.8358e-01,  5.0687e-02,  1.1071e-01, -1.4833e-01],\n",
      "          [-2.4302e-01, -2.2084e-01, -3.9418e-01, -2.8355e-01, -3.9025e-02],\n",
      "          [-4.1312e-01, -2.9276e-01, -3.8612e-01, -3.1111e-01,  1.3988e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.7628e-02,  5.7935e-03,  1.8536e-02, -1.9464e-01, -1.5237e-01],\n",
      "          [-7.3224e-03, -3.0739e-01, -1.1057e-01, -2.7854e-01, -1.7372e-01],\n",
      "          [-2.4382e-01, -6.2190e-02, -2.5501e-01, -2.1805e-01, -2.2865e-01],\n",
      "          [-3.2013e-01, -1.1678e-01, -2.8940e-01, -2.1378e-01, -5.1378e-02],\n",
      "          [ 2.1213e-01, -9.0029e-02,  2.7962e-02, -1.3344e-02,  2.3011e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1680e-01,  7.6159e-02,  1.9139e-01,  1.7860e-02,  1.1063e-01],\n",
      "          [ 7.4618e-02,  1.7227e-02, -1.7449e-01, -1.8554e-01, -2.2309e-01],\n",
      "          [-1.1132e-01, -1.8090e-01, -7.1054e-02, -2.6559e-01, -2.9212e-01],\n",
      "          [-1.1370e-01, -5.5333e-02, -3.1299e-01, -1.9084e-01, -2.1800e-01],\n",
      "          [-1.6793e-02, -2.7591e-01, -4.7343e-02, -1.8163e-01, -1.1592e-01]]]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for para in net.parameters():\n",
    "    print(para)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
